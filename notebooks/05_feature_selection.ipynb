{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a26d63",
   "metadata": {},
   "source": [
    "# Finding and filtering more significant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "315e91c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured: (5742, 9)\n",
      "Text: (5742, 50)\n",
      "Image: (5742, 50)\n",
      "Regression target: (5742,)\n",
      "Classification target: (5742,)\n"
     ]
    }
   ],
   "source": [
    "# we conduct forward selection using sklearn on our saved dataset to find the most significant features for predicting clickability.\n",
    "\n",
    "# --- DATA MANIPULATION ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- STATS ---\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# --- SYSTEM ---\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append('..')\n",
    "RANDOM_SEED = np.random.randint(0, 10000)\n",
    "\n",
    "# --- SET RANDOM SEED ---\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# --- PATHS ---\n",
    "from pathlib import Path\n",
    "base = Path.cwd().parent\n",
    "processed_path = base / \"data\" / \"processed\"\n",
    "\n",
    "# --- Load datasets ---\n",
    "X_structured = pd.read_parquet(processed_path / \"youtube_features_structured.parquet\")\n",
    "X_text = pd.read_parquet(processed_path / \"youtube_features_text.parquet\")\n",
    "X_image = pd.read_parquet(processed_path / \"youtube_features_image.parquet\")\n",
    "y_reg = pd.read_parquet(processed_path / \"youtube_target_regression.parquet\")[\"views_per_subscriber\"]\n",
    "y_clf = pd.read_parquet(processed_path / \"youtube_target_classification.parquet\")[\"high_clickability\"]\n",
    "\n",
    "print(\"Structured:\", X_structured.shape)\n",
    "print(\"Text:\", X_text.shape)\n",
    "print(\"Image:\", X_image.shape)\n",
    "print(\"Regression target:\", y_reg.shape)\n",
    "print(\"Classification target:\", y_clf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10625ed4",
   "metadata": {},
   "source": [
    "# Feature Selection for Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "289935d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected text features for regression task:\n",
      "Index(['tfidf_comp_2', 'tfidf_comp_7', 'tfidf_comp_9', 'tfidf_comp_12',\n",
      "       'tfidf_comp_13', 'tfidf_comp_22', 'tfidf_comp_34', 'tfidf_comp_37',\n",
      "       'tfidf_comp_40', 'tfidf_comp_50'],\n",
      "      dtype='object')\n",
      "Selected text features for classification task:\n",
      "Index(['tfidf_comp_1', 'tfidf_comp_2', 'tfidf_comp_3', 'tfidf_comp_4',\n",
      "       'tfidf_comp_5', 'tfidf_comp_6', 'tfidf_comp_7', 'tfidf_comp_8',\n",
      "       'tfidf_comp_9', 'tfidf_comp_10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# --- ML / NLP --- for text features\n",
    "# perform feature selection using forward selection on text features for regression task as well as classification task\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=20, random_state=RANDOM_SEED)\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select=10, direction='forward', scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "sfs.fit(X_text, y_reg)\n",
    "selected_features_text = X_text.columns[sfs.get_support()]\n",
    "print(\"Selected text features for regression task:\")\n",
    "print(selected_features_text)\n",
    "\n",
    "sfs_clf = SequentialFeatureSelector(model, n_features_to_select=10, direction='forward', scoring='accuracy', cv=5, n_jobs=-1)\n",
    "sfs_clf.fit(X_text, y_clf)\n",
    "selected_features_text_clf = X_text.columns[sfs_clf.get_support()]\n",
    "print(\"Selected text features for classification task:\")\n",
    "print(selected_features_text_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b0061",
   "metadata": {},
   "source": [
    "# Feature Selection for Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e24ca7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mRANDOM_SEED)\n\u001b[0;32m      5\u001b[0m sfs \u001b[38;5;241m=\u001b[39m SequentialFeatureSelector(model, n_features_to_select\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m sfs\u001b[38;5;241m.\u001b[39mfit(X_image, y_reg)\n\u001b[0;32m      7\u001b[0m selected_features_image \u001b[38;5;241m=\u001b[39m X_image\u001b[38;5;241m.\u001b[39mcolumns[sfs\u001b[38;5;241m.\u001b[39mget_support()]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected image features for regression task:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bhada\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bhada\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_sequential.py:282\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    280\u001b[0m     process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[1;32m--> 282\u001b[0m     new_feature_idx, new_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_best_new_feature_score(\n\u001b[0;32m    283\u001b[0m         cloned_estimator, X, y, cv, current_mask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    284\u001b[0m     )\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_auto_select \u001b[38;5;129;01mand\u001b[39;00m ((new_score \u001b[38;5;241m-\u001b[39m old_score) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol):\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bhada\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_sequential.py:313\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[1;34m(self, estimator, X, y, cv, current_mask, **params)\u001b[0m\n\u001b[0;32m    311\u001b[0m         candidate_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcandidate_mask\n\u001b[0;32m    312\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[:, candidate_mask]\n\u001b[1;32m--> 313\u001b[0m     scores[feature_idx] \u001b[38;5;241m=\u001b[39m cross_val_score(\n\u001b[0;32m    314\u001b[0m         estimator,\n\u001b[0;32m    315\u001b[0m         X_new,\n\u001b[0;32m    316\u001b[0m         y,\n\u001b[0;32m    317\u001b[0m         cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    318\u001b[0m         scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring,\n\u001b[0;32m    319\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    320\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    321\u001b[0m     )\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m    322\u001b[0m new_feature_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[1;32mc:\\Users\\bhada\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bhada\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    685\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    686\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    687\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    688\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    689\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    690\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    691\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    692\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    693\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    694\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    695\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    696\u001b[0m )\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bhada\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bhada\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:411\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 411\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    412\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    413\u001b[0m         clone(estimator),\n\u001b[0;32m    414\u001b[0m         X,\n\u001b[0;32m    415\u001b[0m         y,\n\u001b[0;32m    416\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[0;32m    417\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    418\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    419\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    420\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    421\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[0;32m    422\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[0;32m    423\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    424\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    425\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    426\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    427\u001b[0m     )\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    429\u001b[0m )\n\u001b[0;32m    431\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bhada\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\bhada\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\bhada\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bhada\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- ML / NLP --- for image features\n",
    "# perform feature selection using forward selection on image features for regression task as well as classification task\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=20, random_state=RANDOM_SEED)\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select=10, direction='forward', scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "sfs.fit(X_image, y_reg)\n",
    "selected_features_image = X_image.columns[sfs.get_support()]\n",
    "print(\"Selected image features for regression task:\")\n",
    "print(selected_features_image)\n",
    "\n",
    "sfs_clf = SequentialFeatureSelector(model, n_features_to_select=10, direction='forward', scoring='accuracy', cv=5, n_jobs=-1)\n",
    "sfs_clf.fit(X_image, y_clf)\n",
    "selected_features_image_clf = X_image.columns[sfs_clf.get_support()]\n",
    "print(\"Selected image features for classification task:\")\n",
    "print(selected_features_image_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7fdb85",
   "metadata": {},
   "source": [
    "# Feature Selection for Structured Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76560991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ML / NLP --- for text features\n",
    "# perform feature selection using forward selection on text features for regression task as well as classification task\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=20, random_state=RANDOM_SEED)\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select=10, direction='forward', scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "sfs.fit(X_structured, y_reg)\n",
    "selected_features_structured = X_structured.columns[sfs.get_support()]\n",
    "print(\"Selected structured features for regression task:\")\n",
    "print(selected_features_structured)\n",
    "\n",
    "sfs_clf = SequentialFeatureSelector(model, n_features_to_select=10, direction='forward', scoring='accuracy', cv=5, n_jobs=-1)\n",
    "sfs_clf.fit(X_structured, y_clf)\n",
    "selected_features_structured_clf = X_structured.columns[sfs_clf.get_support()]\n",
    "print(\"Selected structured features for classification task:\")\n",
    "print(selected_features_structured_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a1c845",
   "metadata": {},
   "source": [
    "# Making a New Combined Datasets with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bec401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate combined feature set from the selected features for regression task\n",
    "X_combined = pd.concat([X_structured[selected_features_structured].reset_index(drop=True),\n",
    "                        X_text[selected_features_text].reset_index(drop=True),\n",
    "                        X_image[selected_features_image].reset_index(drop=True)], axis=1)\n",
    "print(\"Combined feature matrix:\", X_combined.shape)\n",
    "\n",
    "# Generate combined feature set from the selected features for classification task\n",
    "X_combined_clf = pd.concat([X_structured[selected_features_structured_clf].reset_index(drop=True),\n",
    "                             X_text[selected_features_text_clf].reset_index(drop=True),\n",
    "                             X_image[selected_features_image_clf].reset_index(drop=True)], axis=1)\n",
    "print(\"Combined feature matrix for classification task:\", X_combined_clf.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
