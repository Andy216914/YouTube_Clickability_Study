{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 03_thumbnail_features.ipynb\n",
    "# Extract deep visual features from YouTube thumbnails (ResNet50)\n",
    "# ============================================================\n",
    "\n",
    "# --- System & Data Handling ---\n",
    "import os\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- ML & Feature Extraction ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "# --- Sentiment Analysis (optional) ---\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# --- Dimensionality Reduction ---\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Setup for environment & paths\n",
    "# ============================================================\n",
    "\n",
    "# Detect Apple Silicon GPU or fallback to CPU\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"✅ Using device:\", device)\n",
    "\n",
    "# Set directories\n",
    "base = Path.cwd().parent if (Path.cwd() / \"notebooks\").exists() else Path.cwd()\n",
    "processed_path = base / \"data\" / \"processed\"\n",
    "processed_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResNet50 loaded and ready.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Loads a pretrained deep neural network (ResNet-50) that already knows how to recognize image features from ImageNet.\n",
    "# ============================================================\n",
    "\n",
    "# Load pretrained model (ImageNet)\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet50.fc = nn.Identity()   # remove final classifier\n",
    "resnet50 = resnet50.to(device)\n",
    "resnet50.eval()\n",
    "\n",
    "# Define preprocessing (ImageNet normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Matches ResNet’s expected input shape\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "print(\"✅ ResNet50 loaded and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 5,742 rows and 19 columns.\n",
      "Columns: ['video_id', 'trending_date', 'title', 'channel_title', 'category_id', 'publish_time', 'tags', 'views']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load cleaned dataset from disk into a Pandas DataFrame\n",
    "# ============================================================\n",
    "\n",
    "df_path = Path(\"../data/processed/youtube_clean_final.parquet\")\n",
    "df = pd.read_parquet(df_path) \n",
    "print(f\"✅ Loaded {len(df):,} rows and {len(df.columns)} columns.\")\n",
    "print(\"Columns:\", df.columns[:8].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_url(url: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downloads a thumbnail and returns a 2048-D ResNet50 embedding.\n",
    "    Falls back to zeros if the image is missing or invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(url, str) or not url.startswith(\"http\"):\n",
    "            raise ValueError(\"Invalid URL\")\n",
    "\n",
    "        # Try high-quality thumbnail if available\n",
    "        url_hq = url.replace(\"/default.jpg\", \"/hqdefault.jpg\")\n",
    "\n",
    "        # Download image\n",
    "        response = requests.get(url_hq, timeout=8)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Decode image\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        # Extract ResNet embedding\n",
    "        with torch.no_grad():\n",
    "            features = resnet50(img_tensor).cpu().numpy().flatten()\n",
    "\n",
    "        return features.astype(np.float32)\n",
    "\n",
    "    except (requests.exceptions.RequestException, UnidentifiedImageError, ValueError):\n",
    "        # Return zero vector if any error occurs\n",
    "        return np.zeros(2048, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting ResNet features: 100%|██████████| 5742/5742 [05:34<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to download or decode 526 thumbnails (9.2%)\n",
      "Saved checkpoint: /Users/jinbo/Downloads/YouTube_Clickability_Study/notebooks/data/processed/resnet_raw_features.parquet\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Applies extraction with a progress bar -> visibility into data quality\n",
    "# ============================================================\n",
    "\n",
    "tqdm.pandas(desc=\"Extracting ResNet features\")\n",
    "\n",
    "df[\"resnet_features\"] = df[\"thumbnail_link\"].progress_apply(extract_features_from_url)\n",
    "\n",
    "# Count failed downloads\n",
    "fail_count = sum(np.all(f == 0) for f in df[\"resnet_features\"])\n",
    "print(f\"⚠️ Failed to download or decode {fail_count:,} thumbnails \"\n",
    "      f\"({100*fail_count/len(df):.1f}%)\")\n",
    "\n",
    "# Optional checkpoint\n",
    "tmp_path = processed_path / \"resnet_raw_features.parquet\"\n",
    "df[[\"video_id\", \"resnet_features\"]].to_parquet(tmp_path, index=False)\n",
    "print(\"Saved checkpoint:\", tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 50 old PCA columns...\n",
      "Raw feature matrix shape: (5742, 2048)\n",
      "✅ PCA recomputed → shape: (5742, 50)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Stacks all 2048-D feature vectors into one big matrix.\n",
    "# Uses **PCA** to reduce them to 50 features while keeping most of the important variance (≈ 95 %).\n",
    "# ============================================================\n",
    "# --- Remove old PCA columns ---\n",
    "pca_cols = [c for c in df.columns if c.startswith(\"pca_\")]\n",
    "if pca_cols:\n",
    "    print(f\"Removing {len(pca_cols)} old PCA columns...\")\n",
    "    df = df.drop(columns=pca_cols)\n",
    "    \n",
    "# --- PCA Computation ---\n",
    "X = np.vstack(df[\"resnet_features\"].values)\n",
    "print(\"Raw feature matrix shape:\", X.shape)\n",
    "\n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "df_pca = pd.DataFrame(X_pca, columns=[f\"pca_{i+1}\" for i in range(50)])\n",
    "df = pd.concat([df.reset_index(drop=True), df_pca], axis=1)\n",
    "\n",
    "print(\"✅ PCA recomputed → shape:\", df_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved pure thumbnail dataset to: /Users/jinbo/Downloads/YouTube_Clickability_Study/data/processed/youtube_features_image.parquet\n",
      "Shape: (5742, 50)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Saving the dataset as \"youtube_thumbnail_features.parquet\"\n",
    "# ============================================================\n",
    "# Keep only the PCA columns\n",
    "pca_cols = [f\"pca_{i}\" for i in range(1, 51)]\n",
    "df_pure_image = df[pca_cols].copy()\n",
    "\n",
    "# Define output path\n",
    "out_path = df_path.parent / \"youtube_features_image.parquet\"\n",
    "\n",
    "# Save PCA-only features\n",
    "df_pure_image.to_parquet(out_path, index=False)\n",
    "\n",
    "print(\"✅ Saved pure thumbnail dataset to:\", out_path.resolve())\n",
    "print(\"Shape:\", df_pure_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5,742 rows × 50 columns\n",
      "Sample columns: ['pca_41', 'pca_42', 'pca_43', 'pca_44', 'pca_45', 'pca_46', 'pca_47', 'pca_48', 'pca_49', 'pca_50']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Re-loads and prints shape + tail of column names for testing\n",
    "# ============================================================\n",
    "\n",
    "df_check = pd.read_parquet(out_path)\n",
    "print(f\"Loaded {len(df_check):,} rows × {len(df_check.columns)} columns\")\n",
    "print(\"Sample columns:\", df_check.columns[-10:].to_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_hw1)",
   "language": "python",
   "name": "ml_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
