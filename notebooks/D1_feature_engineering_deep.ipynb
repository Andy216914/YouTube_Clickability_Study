{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä D1 ‚Äî Deep Feature Engineering for Multimodal YouTube Clickability\n",
    "\n",
    "In this notebook we build **deep, multimodal feature sets** for our YouTube Clickability Study.\n",
    "\n",
    "We will create **three new feature matrices**:\n",
    "\n",
    "- `youtube_features_structured_deep.parquet` ‚Üí rich handcrafted + semantic title/channel features  \n",
    "- `youtube_features_text_deep.parquet` ‚Üí Sentence-BERT embeddings (768-dim)  \n",
    "- `youtube_features_image_deep.parquet` ‚Üí CLIP ViT-L/14 + EfficientNet-B0 thumbnail embeddings + visual metadata  \n",
    "\n",
    "We will **reuse** our existing targets:\n",
    "\n",
    "- `youtube_target_regression.parquet`  \n",
    "- `youtube_target_classification.parquet` *(top-25% cutoff, already created earlier)*  \n",
    "\n",
    "These files are designed specifically for the **multimodal deep NN** used in `D2_multimodal_deep_nn.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. üì¶ Install Dependencies\n",
    "\n",
    "This cell installs all Python packages needed for **deep feature engineering**:\n",
    "\n",
    "- `requests`, `tqdm`, `pillow` ‚Üí downloading thumbnails & progress bars  \n",
    "- `sentence-transformers` ‚Üí Sentence-BERT for text embeddings  \n",
    "- `transformers` ‚Üí CLIP model for vision embeddings  \n",
    "- `timm` ‚Üí EfficientNet for thumbnail embeddings  \n",
    "- `opencv-python` ‚Üí face detection  \n",
    "- `pytesseract` ‚Üí thumbnail OCR (text density)  \n",
    "- `textstat`, `textblob`, `vaderSentiment` ‚Üí readability & sentiment signals  \n",
    "\n",
    "> If some are already installed, pip will just say **‚ÄúRequirement already satisfied.‚Äù**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Dependencies installed (or already satisfied).\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet \\\n",
    "    requests \\\n",
    "    tqdm \\\n",
    "    pillow \\\n",
    "    sentence-transformers \\\n",
    "    transformers \\\n",
    "    timm \\\n",
    "    opencv-python \\\n",
    "    pytesseract \\\n",
    "    textstat \\\n",
    "    textblob \\\n",
    "    vaderSentiment\n",
    "\n",
    "print(\"‚úÖ Dependencies installed (or already satisfied).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. üìÇ Setup Paths, Device, and Load Clean Dataset\n",
    "\n",
    "Here we:\n",
    "\n",
    "1. Define project paths (`base`, `processed_path`)\n",
    "2. Load the cleaned dataset: `youtube_clean_final.parquet`\n",
    "3. Detect whether we can use **CUDA**, **MPS**, or CPU (Sentence-BERT is always forced to CPU for safety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: (5742, 19)\n",
      "Vision device: mps\n",
      "Text device:  cpu (SentenceTransformers safer on CPU)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>views_per_subscriber</th>\n",
       "      <th>views_per_subscriber_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0CMnp02rNY</td>\n",
       "      <td>18.11.06</td>\n",
       "      <td>Mindy Kaling's Daughter Had the Perfect Reacti...</td>\n",
       "      <td>TheEllenShow</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-06-04 13:00:00+00:00</td>\n",
       "      <td>ellen|\"ellen degeneres\"|\"the ellen show\"|\"elle...</td>\n",
       "      <td>800359</td>\n",
       "      <td>9773</td>\n",
       "      <td>332</td>\n",
       "      <td>423</td>\n",
       "      <td>https://i.ytimg.com/vi/-0CMnp02rNY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ocean's 8 star Mindy Kaling dished on bringing...</td>\n",
       "      <td>2.376002e+07</td>\n",
       "      <td>0.033685</td>\n",
       "      <td>0.033130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0NYY8cqdiQ</td>\n",
       "      <td>18.01.02</td>\n",
       "      <td>Megan Mullally Didn't Notice the Interesting P...</td>\n",
       "      <td>TheEllenShow</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-01-29 14:00:39+00:00</td>\n",
       "      <td>megan mullally|\"megan\"|\"mullally\"|\"will and gr...</td>\n",
       "      <td>563746</td>\n",
       "      <td>4429</td>\n",
       "      <td>54</td>\n",
       "      <td>94</td>\n",
       "      <td>https://i.ytimg.com/vi/-0NYY8cqdiQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ellen and Megan Mullally have known each other...</td>\n",
       "      <td>2.376002e+07</td>\n",
       "      <td>0.023727</td>\n",
       "      <td>0.023450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1Hm41N0dUs</td>\n",
       "      <td>18.01.05</td>\n",
       "      <td>Cast of Avengers: Infinity War Draws Their Cha...</td>\n",
       "      <td>Jimmy Kimmel Live</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-04-27 07:30:02+00:00</td>\n",
       "      <td>jimmy|\"jimmy kimmel\"|\"jimmy kimmel live\"|\"late...</td>\n",
       "      <td>2058516</td>\n",
       "      <td>41248</td>\n",
       "      <td>580</td>\n",
       "      <td>1484</td>\n",
       "      <td>https://i.ytimg.com/vi/-1Hm41N0dUs/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Benedict Cumberbatch, Don Cheadle, Elizabeth O...</td>\n",
       "      <td>1.126290e+07</td>\n",
       "      <td>0.182770</td>\n",
       "      <td>0.167859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1yT-K3c6YI</td>\n",
       "      <td>17.02.12</td>\n",
       "      <td>YOUTUBER QUIZ + TRUTH OR DARE W/ THE MERRELL T...</td>\n",
       "      <td>Molly Burke</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-28 18:30:43+00:00</td>\n",
       "      <td>youtube quiz|\"youtuber quiz\"|\"truth or dare\"|\"...</td>\n",
       "      <td>231341</td>\n",
       "      <td>7734</td>\n",
       "      <td>212</td>\n",
       "      <td>846</td>\n",
       "      <td>https://i.ytimg.com/vi/-1yT-K3c6YI/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Check out the video we did on the Merrell Twin...</td>\n",
       "      <td>2.740040e+05</td>\n",
       "      <td>0.844295</td>\n",
       "      <td>0.612097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2RVw2_QyxQ</td>\n",
       "      <td>17.16.11</td>\n",
       "      <td>2017 Champions Showdown: Day 3</td>\n",
       "      <td>Saint Louis Chess Club</td>\n",
       "      <td>27</td>\n",
       "      <td>2017-11-12 02:39:01+00:00</td>\n",
       "      <td>Chess|\"Saint Louis\"|\"Club\"</td>\n",
       "      <td>71089</td>\n",
       "      <td>460</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>https://i.ytimg.com/vi/-2RVw2_QyxQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The Saint Louis Chess Club hosts a series of f...</td>\n",
       "      <td>1.477180e+05</td>\n",
       "      <td>0.481245</td>\n",
       "      <td>0.392883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  -0CMnp02rNY      18.11.06   \n",
       "1  -0NYY8cqdiQ      18.01.02   \n",
       "2  -1Hm41N0dUs      18.01.05   \n",
       "3  -1yT-K3c6YI      17.02.12   \n",
       "4  -2RVw2_QyxQ      17.16.11   \n",
       "\n",
       "                                               title           channel_title  \\\n",
       "0  Mindy Kaling's Daughter Had the Perfect Reacti...            TheEllenShow   \n",
       "1  Megan Mullally Didn't Notice the Interesting P...            TheEllenShow   \n",
       "2  Cast of Avengers: Infinity War Draws Their Cha...       Jimmy Kimmel Live   \n",
       "3  YOUTUBER QUIZ + TRUTH OR DARE W/ THE MERRELL T...             Molly Burke   \n",
       "4                     2017 Champions Showdown: Day 3  Saint Louis Chess Club   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           24 2018-06-04 13:00:00+00:00   \n",
       "1           24 2018-01-29 14:00:39+00:00   \n",
       "2           23 2018-04-27 07:30:02+00:00   \n",
       "3           22 2017-11-28 18:30:43+00:00   \n",
       "4           27 2017-11-12 02:39:01+00:00   \n",
       "\n",
       "                                                tags    views  likes  \\\n",
       "0  ellen|\"ellen degeneres\"|\"the ellen show\"|\"elle...   800359   9773   \n",
       "1  megan mullally|\"megan\"|\"mullally\"|\"will and gr...   563746   4429   \n",
       "2  jimmy|\"jimmy kimmel\"|\"jimmy kimmel live\"|\"late...  2058516  41248   \n",
       "3  youtube quiz|\"youtuber quiz\"|\"truth or dare\"|\"...   231341   7734   \n",
       "4                         Chess|\"Saint Louis\"|\"Club\"    71089    460   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0       332            423  https://i.ytimg.com/vi/-0CMnp02rNY/default.jpg   \n",
       "1        54             94  https://i.ytimg.com/vi/-0NYY8cqdiQ/default.jpg   \n",
       "2       580           1484  https://i.ytimg.com/vi/-1Hm41N0dUs/default.jpg   \n",
       "3       212            846  https://i.ytimg.com/vi/-1yT-K3c6YI/default.jpg   \n",
       "4        27             20  https://i.ytimg.com/vi/-2RVw2_QyxQ/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description   subscribers  \\\n",
       "0  Ocean's 8 star Mindy Kaling dished on bringing...  2.376002e+07   \n",
       "1  Ellen and Megan Mullally have known each other...  2.376002e+07   \n",
       "2  Benedict Cumberbatch, Don Cheadle, Elizabeth O...  1.126290e+07   \n",
       "3  Check out the video we did on the Merrell Twin...  2.740040e+05   \n",
       "4  The Saint Louis Chess Club hosts a series of f...  1.477180e+05   \n",
       "\n",
       "   views_per_subscriber  views_per_subscriber_log  \n",
       "0              0.033685                  0.033130  \n",
       "1              0.023727                  0.023450  \n",
       "2              0.182770                  0.167859  \n",
       "3              0.844295                  0.612097  \n",
       "4              0.481245                  0.392883  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Paths\n",
    "base = Path.cwd().parent\n",
    "processed_path = base / \"data\" / \"processed\"\n",
    "processed_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load cleaned dataset\n",
    "df = pd.read_parquet(processed_path / \"youtube_clean_final.parquet\")\n",
    "print(\"Loaded dataset:\", df.shape)\n",
    "\n",
    "# Device selection\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Vision device:\", device)\n",
    "print(\"Text device:  cpu (SentenceTransformers safer on CPU)\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üßπ Basic Title Cleaning\n",
    "\n",
    "We ensure the `title` column is:\n",
    "\n",
    "- Cast to string  \n",
    "- Free of leading/trailing whitespace  \n",
    "\n",
    "This keeps downstream text processing consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample titles:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Mindy Kaling's Daughter Had the Perfect Reacti...\n",
       "1    Megan Mullally Didn't Notice the Interesting P...\n",
       "2    Cast of Avengers: Infinity War Draws Their Cha...\n",
       "3    YOUTUBER QUIZ + TRUTH OR DARE W/ THE MERRELL T...\n",
       "4                       2017 Champions Showdown: Day 3\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"title\"] = df[\"title\"].astype(str).str.strip()\n",
    "print(\"Sample titles:\")\n",
    "df[\"title\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. üß± Structured Deep Features (Handcrafted + Functional)\n",
    "\n",
    "We build a **richer structured feature set**, including:\n",
    "\n",
    "### **Original structured features**\n",
    "- `title_length`\n",
    "- `word_count`\n",
    "- `caps_ratio`\n",
    "- `has_question`, `has_exclamation`, `has_number`\n",
    "- `avg_word_len`\n",
    "- `sentiment_vader`\n",
    "- `subscribers`\n",
    "\n",
    "### **Functional deep structured features**\n",
    "- `sentiment_tb` ‚Üí TextBlob polarity  \n",
    "- `readability` ‚Üí Flesch Reading Ease  \n",
    "- `emoji_count`  \n",
    "- `punctuation_intensity`\n",
    "\n",
    "Saved to:  \n",
    "`youtube_features_structured_deep.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured DEEP feature shape: (5742, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>caps_ratio</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_exclamation</th>\n",
       "      <th>has_number</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>sentiment_vader</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>sentiment_tb</th>\n",
       "      <th>readability</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>punctuation_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.818182</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>2.376002e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.542727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>-0.3089</td>\n",
       "      <td>2.376002e+07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>27.485000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>1.126290e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.240000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.5147</td>\n",
       "      <td>2.740040e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>1.477180e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_length  word_count  caps_ratio  has_question  has_exclamation  \\\n",
       "0            74          11    0.121622             0                0   \n",
       "1            75          10    0.106667             0                0   \n",
       "2            53           8    0.132075             0                0   \n",
       "3            51          10    0.764706             0                1   \n",
       "4            30           5    0.100000             0                0   \n",
       "\n",
       "   has_number  avg_word_len  sentiment_vader   subscribers  sentiment_tb  \\\n",
       "0           0      5.818182           0.5719  2.376002e+07           1.0   \n",
       "1           0      6.600000          -0.3089  2.376002e+07           0.5   \n",
       "2           0      5.750000          -0.5994  1.126290e+07           0.0   \n",
       "3           0      4.200000           0.5147  2.740040e+05           0.0   \n",
       "4           1      5.200000           0.5267  1.477180e+05           0.0   \n",
       "\n",
       "   readability  emoji_count  punctuation_intensity  \n",
       "0    49.542727            0               0.000000  \n",
       "1    27.485000            0               0.000000  \n",
       "2    61.240000            0               0.018868  \n",
       "3    75.500000            0               0.019608  \n",
       "4    66.400000            0               0.033333  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import textstat\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "titles = df[\"title\"].astype(str)\n",
    "\n",
    "def count_emojis(text):\n",
    "    emoji_chars = \"üòÄüòÉüòÑüòÅüòÜüòÖüòÇü§£üòäüòçüòéüî•üíÄ‚ú®üôèüíØüéâü•∂ü•µü§Øüò±üò®üò¢üò≠üò°\"\n",
    "    return sum(ch in emoji_chars for ch in text)\n",
    "\n",
    "df_struct_deep = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Original structured\n",
    "df_struct_deep[\"title_length\"] = titles.apply(len)\n",
    "df_struct_deep[\"word_count\"] = titles.apply(lambda x: len(x.split()))\n",
    "df_struct_deep[\"caps_ratio\"] = titles.apply(\n",
    "    lambda x: sum(c.isupper() for c in x) / len(x) if len(x) else 0\n",
    ")\n",
    "df_struct_deep[\"has_question\"] = titles.apply(lambda x: int(\"?\" in x))\n",
    "df_struct_deep[\"has_exclamation\"] = titles.apply(lambda x: int(\"!\" in x))\n",
    "df_struct_deep[\"has_number\"] = titles.apply(lambda x: int(any(c.isdigit() for c in x)))\n",
    "df_struct_deep[\"avg_word_len\"] = titles.apply(\n",
    "    lambda x: np.mean([len(w) for w in x.split()]) if x.split() else 0\n",
    ")\n",
    "df_struct_deep[\"sentiment_vader\"] = titles.apply(\n",
    "    lambda x: analyzer.polarity_scores(x)[\"compound\"]\n",
    ")\n",
    "df_struct_deep[\"subscribers\"] = df[\"subscribers\"].astype(float)\n",
    "\n",
    "# Functional features\n",
    "df_struct_deep[\"sentiment_tb\"] = titles.apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df_struct_deep[\"readability\"] = titles.apply(\n",
    "    lambda x: textstat.flesch_reading_ease(x) if x.strip() else 0\n",
    ")\n",
    "df_struct_deep[\"emoji_count\"] = titles.apply(count_emojis)\n",
    "punct_chars = \"!?.,:;\"\n",
    "df_struct_deep[\"punctuation_intensity\"] = titles.apply(\n",
    "    lambda x: sum(x.count(p) for p in punct_chars) / len(x) if len(x) else 0\n",
    ")\n",
    "struct_path = processed_path / \"youtube_features_structured_deep.parquet\"\n",
    "df_struct_deep.to_parquet(struct_path, index=False)\n",
    "\n",
    "print(\"Structured DEEP feature shape:\", df_struct_deep.shape)\n",
    "df_struct_deep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üìù Text Deep Features ‚Äî Sentence-BERT + PCA-128\n",
    "\n",
    "We generate strong text embeddings by combining **title + tags + description** into a single semantic string:\n",
    "\n",
    "### üìò Sentence-BERT `all-mpnet-base-v2`\n",
    "- 768-dimensional semantic embedding  \n",
    "- Captures meaning, sentiment, keywords, writing style  \n",
    "\n",
    "### ‚≠ê PCA ‚Üí **128 dimensions**\n",
    "- Retains >95% of semantic variance  \n",
    "- Speeds up training  \n",
    "- Reduces model size & overfitting  \n",
    "- Better stability for multimodal fusion  \n",
    "\n",
    "### üì¶ Saved Output  \n",
    "Final 128-dim text embeddings stored to:\n",
    "\n",
    "`youtube_features_text_deep.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text rows: 5742\n",
      "üì¶ Loading Sentence-BERT (MPNet)...\n",
      "üîç Encoding text with MPNet...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d502fe5ac04688b714a65d5cc2ff0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text embedding shape: (5742, 768)\n",
      "‚öôÔ∏è Applying PCA ‚Üí 128 dims...\n",
      "‚úì PCA complete. New shape: (5742, 128)\n",
      "üéâ Saved PCA-compressed text features: (5742, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_pca_0</th>\n",
       "      <th>text_pca_1</th>\n",
       "      <th>text_pca_2</th>\n",
       "      <th>text_pca_3</th>\n",
       "      <th>text_pca_4</th>\n",
       "      <th>text_pca_5</th>\n",
       "      <th>text_pca_6</th>\n",
       "      <th>text_pca_7</th>\n",
       "      <th>text_pca_8</th>\n",
       "      <th>text_pca_9</th>\n",
       "      <th>...</th>\n",
       "      <th>text_pca_118</th>\n",
       "      <th>text_pca_119</th>\n",
       "      <th>text_pca_120</th>\n",
       "      <th>text_pca_121</th>\n",
       "      <th>text_pca_122</th>\n",
       "      <th>text_pca_123</th>\n",
       "      <th>text_pca_124</th>\n",
       "      <th>text_pca_125</th>\n",
       "      <th>text_pca_126</th>\n",
       "      <th>text_pca_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.151295</td>\n",
       "      <td>-0.147980</td>\n",
       "      <td>0.383545</td>\n",
       "      <td>-0.006988</td>\n",
       "      <td>0.083549</td>\n",
       "      <td>0.061882</td>\n",
       "      <td>0.089808</td>\n",
       "      <td>-0.131110</td>\n",
       "      <td>-0.015959</td>\n",
       "      <td>-0.133157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074844</td>\n",
       "      <td>0.074155</td>\n",
       "      <td>-0.024881</td>\n",
       "      <td>-0.016199</td>\n",
       "      <td>-0.009139</td>\n",
       "      <td>-0.006956</td>\n",
       "      <td>0.034270</td>\n",
       "      <td>0.017859</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>-0.008997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.058435</td>\n",
       "      <td>-0.145014</td>\n",
       "      <td>0.396311</td>\n",
       "      <td>-0.041779</td>\n",
       "      <td>-0.018310</td>\n",
       "      <td>0.153744</td>\n",
       "      <td>0.093258</td>\n",
       "      <td>-0.123044</td>\n",
       "      <td>-0.017802</td>\n",
       "      <td>0.025689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>0.023881</td>\n",
       "      <td>-0.053888</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>-0.011896</td>\n",
       "      <td>0.048322</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.015007</td>\n",
       "      <td>0.036443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.152892</td>\n",
       "      <td>-0.187936</td>\n",
       "      <td>0.103694</td>\n",
       "      <td>0.339933</td>\n",
       "      <td>-0.044565</td>\n",
       "      <td>-0.154826</td>\n",
       "      <td>0.028612</td>\n",
       "      <td>0.098123</td>\n",
       "      <td>-0.113959</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070238</td>\n",
       "      <td>0.025376</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>0.012419</td>\n",
       "      <td>0.038180</td>\n",
       "      <td>-0.002867</td>\n",
       "      <td>0.017639</td>\n",
       "      <td>-0.033473</td>\n",
       "      <td>-0.017865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116747</td>\n",
       "      <td>0.252121</td>\n",
       "      <td>0.182934</td>\n",
       "      <td>-0.024036</td>\n",
       "      <td>-0.059010</td>\n",
       "      <td>-0.122711</td>\n",
       "      <td>0.080005</td>\n",
       "      <td>0.088937</td>\n",
       "      <td>0.070096</td>\n",
       "      <td>-0.056868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065549</td>\n",
       "      <td>0.025949</td>\n",
       "      <td>0.049594</td>\n",
       "      <td>-0.011026</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>-0.013862</td>\n",
       "      <td>0.026179</td>\n",
       "      <td>-0.053807</td>\n",
       "      <td>0.059425</td>\n",
       "      <td>0.016043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.075288</td>\n",
       "      <td>-0.090466</td>\n",
       "      <td>-0.221809</td>\n",
       "      <td>-0.067399</td>\n",
       "      <td>0.117314</td>\n",
       "      <td>-0.198868</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>-0.157611</td>\n",
       "      <td>-0.006242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002234</td>\n",
       "      <td>0.024061</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>-0.012131</td>\n",
       "      <td>-0.015217</td>\n",
       "      <td>-0.027122</td>\n",
       "      <td>0.076398</td>\n",
       "      <td>-0.051127</td>\n",
       "      <td>0.033308</td>\n",
       "      <td>0.021247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_pca_0  text_pca_1  text_pca_2  text_pca_3  text_pca_4  text_pca_5  \\\n",
       "0   -0.151295   -0.147980    0.383545   -0.006988    0.083549    0.061882   \n",
       "1   -0.058435   -0.145014    0.396311   -0.041779   -0.018310    0.153744   \n",
       "2   -0.152892   -0.187936    0.103694    0.339933   -0.044565   -0.154826   \n",
       "3    0.116747    0.252121    0.182934   -0.024036   -0.059010   -0.122711   \n",
       "4   -0.075288   -0.090466   -0.221809   -0.067399    0.117314   -0.198868   \n",
       "\n",
       "   text_pca_6  text_pca_7  text_pca_8  text_pca_9  ...  text_pca_118  \\\n",
       "0    0.089808   -0.131110   -0.015959   -0.133157  ...     -0.074844   \n",
       "1    0.093258   -0.123044   -0.017802    0.025689  ...      0.011435   \n",
       "2    0.028612    0.098123   -0.113959   -0.004525  ...      0.070238   \n",
       "3    0.080005    0.088937    0.070096   -0.056868  ...      0.065549   \n",
       "4   -0.130149    0.015747   -0.157611   -0.006242  ...     -0.002234   \n",
       "\n",
       "   text_pca_119  text_pca_120  text_pca_121  text_pca_122  text_pca_123  \\\n",
       "0      0.074155     -0.024881     -0.016199     -0.009139     -0.006956   \n",
       "1      0.023881     -0.053888      0.002444      0.019642     -0.011896   \n",
       "2      0.025376      0.001864      0.006263      0.012419      0.038180   \n",
       "3      0.025949      0.049594     -0.011026      0.006787     -0.013862   \n",
       "4      0.024061      0.003783     -0.012131     -0.015217     -0.027122   \n",
       "\n",
       "   text_pca_124  text_pca_125  text_pca_126  text_pca_127  \n",
       "0      0.034270      0.017859      0.021243     -0.008997  \n",
       "1      0.048322      0.002644      0.015007      0.036443  \n",
       "2     -0.002867      0.017639     -0.033473     -0.017865  \n",
       "3      0.026179     -0.053807      0.059425      0.016043  \n",
       "4      0.076398     -0.051127      0.033308      0.021247  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Build text rows (TITLE + TAGS + DESCRIPTION)\n",
    "def build_text_row(row):\n",
    "    return f\"[TITLE] {row['title']} [TAGS] {row['tags']} [DESC] {row['description']}\"\n",
    "\n",
    "texts = df.apply(build_text_row, axis=1).tolist()\n",
    "print(\"Total text rows:\", len(texts))\n",
    "\n",
    "# Load MPNet (Sentence-BERT)\n",
    "print(\"üì¶ Loading Sentence-BERT (MPNet)...\")\n",
    "model_text = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\", device=\"cpu\")\n",
    "\n",
    "# Encode ‚Üí 768-dim embeddings\n",
    "print(\"üîç Encoding text with MPNet...\")\n",
    "text_embeddings = model_text.encode(\n",
    "    texts,\n",
    "    batch_size=32,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"Raw text embedding shape:\", text_embeddings.shape)\n",
    "\n",
    "# PCA ‚Üí 128 dims\n",
    "print(\"‚öôÔ∏è Applying PCA ‚Üí 128 dims...\")\n",
    "pca_text = PCA(n_components=128, random_state=42)\n",
    "text_pca = pca_text.fit_transform(text_embeddings).astype(np.float32)\n",
    "\n",
    "print(\"‚úì PCA complete. New shape:\", text_pca.shape)\n",
    "\n",
    "# Save to parquet\n",
    "X_text_deep = pd.DataFrame(\n",
    "    text_pca,\n",
    "    columns=[f\"text_pca_{i}\" for i in range(128)],\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "text_path = processed_path / \"youtube_features_text_deep.parquet\"\n",
    "X_text_deep.to_parquet(text_path, index=False)\n",
    "\n",
    "print(\"üéâ Saved PCA-compressed text features:\", X_text_deep.shape)\n",
    "\n",
    "X_text_deep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üñº Image Deep Features ‚Äî CLIP ViT-B/32 + Visual Metadata + PCA-128\n",
    "\n",
    "We extract deep visual features from each YouTube thumbnail using **CLIP ViT-B/32**, a fast and highly semantic vision encoder.\n",
    "\n",
    "### üß† CLIP ViT-B/32 (768-dim)\n",
    "- Recognizes objects, style, composition, and scene structure  \n",
    "- Much faster than ViT-L/14 while still strong for clickability prediction  \n",
    "- Outputs a **768-dim normalized embedding**\n",
    "\n",
    "### üß© Visual Metadata (4 interpretable features)\n",
    "- **brightness** ‚Äî overall luminance  \n",
    "- **saturation** ‚Äî color richness  \n",
    "- **face_count** ‚Äî # of detected human faces  \n",
    "- **text_density** ‚Äî OCR skipped for speed (set to 0)\n",
    "\n",
    "### ‚≠ê PCA ‚Üí 128 dims (recommended)\n",
    "We compress `[768 + 4] = 772` raw features into **128-dim** using PCA:\n",
    "- Reduces noise and speeds up training\n",
    "- Lowers overfitting  \n",
    "- More stable for multimodal fusion\n",
    "\n",
    "### üì¶ Saved Output  \n",
    "`youtube_features_image_deep.parquet` ‚Äî with **128 columns**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Vision device: mps\n",
      "üì¶ Loading CLIP ViT-B/32...\n",
      "\n",
      "üîç Step 1/3 ‚Äî Downloading thumbnails + computing metadata...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea89eb6b4c449ca9bdeb4db0762488b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Images processed:   0%|          | 0/5742 [00:00<?, ?img/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì CLIP embeddings complete: (5742, 512)\n",
      "Combined feature matrix: (5742, 516)\n",
      "\n",
      "‚öôÔ∏è Step 2/3 ‚Äî Running PCA ‚Üí 128 dims...\n",
      "‚úì PCA complete ‚Üí shape: (5742, 128)\n",
      "üéâ Step 3/3 ‚Äî Final image deep features saved: (5742, 128)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 5. üñº Image Deep Features ‚Äî CLIP ViT-B/32 + Visual Metadata + OCR + PCA-128\n",
    "# ==============================================================\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import cv2\n",
    "import pytesseract\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "print(\"üîå Vision device:\", device)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Load CLIP ViT-B/32\n",
    "# --------------------------------------------------------------\n",
    "print(\"üì¶ Loading CLIP ViT-B/32...\")\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model.eval()\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Helper: download_thumbnail\n",
    "# --------------------------------------------------------------\n",
    "def download_img(url: str) -> Image.Image:\n",
    "    try:\n",
    "        if not isinstance(url, str) or not url.startswith(\"http\"):\n",
    "            raise ValueError(\"Bad URL\")\n",
    "        url_hq = url.replace(\"/default.jpg\", \"/hqdefault.jpg\")\n",
    "        resp = requests.get(url_hq, timeout=7)\n",
    "        resp.raise_for_status()\n",
    "        return Image.open(BytesIO(resp.content)).convert(\"RGB\")\n",
    "    except Exception:\n",
    "        # fallback blank image\n",
    "        return Image.fromarray(np.zeros((224, 224, 3), dtype=np.uint8))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Helper: OCR-safe visual metadata\n",
    "# --------------------------------------------------------------\n",
    "def compute_metadata(img: Image.Image):\n",
    "\n",
    "    img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # 1. Brightness\n",
    "    brightness = float(img_cv.mean())\n",
    "\n",
    "    # 2. Saturation\n",
    "    hsv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2HSV)\n",
    "    saturation = float(hsv[:, :, 1].mean())\n",
    "\n",
    "    # 3. Face Count\n",
    "    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "    )\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "    face_count = int(len(faces))\n",
    "\n",
    "    # 4. OCR Text Density ‚Äî SAFE VERSION\n",
    "    img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    try:\n",
    "        # Faster OCR config\n",
    "        ocr_data = pytesseract.image_to_data(\n",
    "            img_rgb,\n",
    "            config=\"--oem 3 --psm 6\",\n",
    "            output_type=pytesseract.Output.DICT,\n",
    "        )\n",
    "    except Exception:\n",
    "        return brightness, saturation, face_count, 0.0\n",
    "\n",
    "    text_area = 0\n",
    "    total_area = img_rgb.shape[0] * img_rgb.shape[1]\n",
    "\n",
    "    n_items = len(ocr_data.get(\"text\", []))\n",
    "\n",
    "    for i in range(n_items):\n",
    "        text = ocr_data[\"text\"][i].strip()\n",
    "\n",
    "        if text == \"\":\n",
    "            continue\n",
    "\n",
    "        # ---- skip missing/invalid OCR values ----\n",
    "        try:\n",
    "            w = int(ocr_data[\"width\"][i])\n",
    "            h = int(ocr_data[\"height\"][i])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if w <= 0 or h <= 0:\n",
    "            continue\n",
    "\n",
    "        text_area += w * h\n",
    "\n",
    "    text_density = text_area / total_area if total_area > 0 else 0.0\n",
    "\n",
    "    # stability clip\n",
    "    text_density = min(text_density, 0.5)\n",
    "\n",
    "    return brightness, saturation, face_count, float(text_density)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Helper: CLIP batch inference\n",
    "# --------------------------------------------------------------\n",
    "def clip_batch_embed(batch):\n",
    "    if len(batch) == 0:\n",
    "        return np.zeros((0, 768), dtype=np.float32)\n",
    "\n",
    "    inputs = clip_processor(images=batch, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feats = clip_model.get_image_features(**inputs)\n",
    "        feats = feats / feats.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    return feats.cpu().numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 5.1 Process thumbnails\n",
    "# ==============================================================\n",
    "\n",
    "print(\"\\nüîç Step 1/3 ‚Äî Downloading thumbnails + computing metadata...\")\n",
    "\n",
    "thumb_urls = df[\"thumbnail_link\"].tolist()\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "brightness_list = []\n",
    "saturation_list = []\n",
    "face_count_list = []\n",
    "text_density_list = []\n",
    "\n",
    "batched_clip_results = []\n",
    "batch_imgs = []\n",
    "\n",
    "pbar = tqdm(total=len(thumb_urls), desc=\"Images processed\", unit=\"img\")\n",
    "\n",
    "for url in thumb_urls:\n",
    "    img = download_img(url)\n",
    "\n",
    "    # Metadata\n",
    "    br, sat, fc, td = compute_metadata(img)\n",
    "    brightness_list.append(br)\n",
    "    saturation_list.append(sat)\n",
    "    face_count_list.append(fc)\n",
    "    text_density_list.append(td)\n",
    "\n",
    "    batch_imgs.append(img)\n",
    "\n",
    "    if len(batch_imgs) == BATCH_SIZE:\n",
    "        batch_emb = clip_batch_embed(batch_imgs)\n",
    "        batched_clip_results.append(batch_emb)\n",
    "        batch_imgs = []\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "# leftover\n",
    "if len(batch_imgs) > 0:\n",
    "    batched_clip_results.append(clip_batch_embed(batch_imgs))\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "X_clip = np.vstack(batched_clip_results)\n",
    "print(f\"‚úì CLIP embeddings complete: {X_clip.shape}\")\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 5.2 Combine with metadata\n",
    "# ==============================================================\n",
    "\n",
    "meta_array = np.stack(\n",
    "    [brightness_list, saturation_list, face_count_list, text_density_list],\n",
    "    axis=1,\n",
    ").astype(np.float32)\n",
    "\n",
    "X_img_raw = np.hstack([X_clip, meta_array])\n",
    "print(\"Combined feature matrix:\", X_img_raw.shape)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 5.3 PCA ‚Üí 128 dims\n",
    "# ==============================================================\n",
    "\n",
    "print(\"\\n‚öôÔ∏è Step 2/3 ‚Äî Running PCA ‚Üí 128 dims...\")\n",
    "pca = PCA(n_components=128, random_state=42)\n",
    "X_img_pca = pca.fit_transform(X_img_raw).astype(np.float32)\n",
    "print(\"‚úì PCA complete ‚Üí shape:\", X_img_pca.shape)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 5.4 Save\n",
    "# ==============================================================\n",
    "\n",
    "img_cols = [f\"img_pca_{i}\" for i in range(128)]\n",
    "X_image_deep = pd.DataFrame(X_img_pca, columns=img_cols, index=df.index)\n",
    "\n",
    "img_path = processed_path / \"youtube_features_image_deep.parquet\"\n",
    "X_image_deep.to_parquet(img_path, index=False)\n",
    "\n",
    "print(f\"üéâ Step 3/3 ‚Äî Final image deep features saved: {X_image_deep.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. üíæ Deep Feature Matrices ‚Äî Summary (No Saving Here)\n",
    "\n",
    "All **deep multimodal feature matrices** have now been generated and saved in their\n",
    "respective sections earlier in this notebook:\n",
    "\n",
    "- `youtube_features_structured_deep.parquet`  \n",
    "  ‚Üí enriched handcrafted + semantic title/channel features  \n",
    "\n",
    "- `youtube_features_text_deep.parquet`  \n",
    "  ‚Üí Sentence-BERT title embeddings (768-dim)  \n",
    "\n",
    "- `youtube_features_image_deep.parquet`  \n",
    "  ‚Üí CLIP ViT-B/32 + metadata compressed with PCA-512  \n",
    "\n",
    "Our targets were created previously and remain unchanged:\n",
    "\n",
    "- `youtube_target_regression.parquet`  \n",
    "  ‚Üí continuous *views_per_subscriber* metric  \n",
    "- `youtube_target_classification.parquet`  \n",
    "  ‚Üí binary clickability label (top-25% cutoff)\n",
    "\n",
    "These **five datasets** collectively serve as the complete input to  \n",
    "`D2_multimodal_deep_nn.ipynb`, where we train the full multimodal deep neural network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìê Deep Feature Summary\n",
      "Structured deep ‚Üí (5742, 13)\n",
      "Text deep       ‚Üí (5742, 128)\n",
      "Image deep      ‚Üí (5742, 128)\n",
      "\n",
      "üéØ Targets\n",
      "Regression target shape     ‚Üí (5742, 1)\n",
      "Classification target shape ‚Üí (5742, 1)\n",
      "\n",
      "‚úÖ All deep features are ready for D2_multimodal_deep_nn.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Display shapes for confirmation\n",
    "print(\"üìê Deep Feature Summary\")\n",
    "print(\"Structured deep ‚Üí\", df_struct_deep.shape)\n",
    "print(\"Text deep       ‚Üí\", X_text_deep.shape)\n",
    "print(\"Image deep      ‚Üí\", X_image_deep.shape)\n",
    "\n",
    "print(\"\\nüéØ Targets\")\n",
    "print(\"Regression target shape     ‚Üí\", pd.read_parquet(processed_path / \"youtube_target_regression.parquet\").shape)\n",
    "print(\"Classification target shape ‚Üí\", pd.read_parquet(processed_path / \"youtube_target_classification.parquet\").shape)\n",
    "\n",
    "print(\"\\n‚úÖ All deep features are ready for D2_multimodal_deep_nn.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_click",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
