{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b88559",
   "metadata": {},
   "source": [
    "# Setup & Load Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Setup & Environment for Feature Engineering\n",
    "# Generates 5 datasets:\n",
    "# structured, text, image, regression, classification\n",
    "# ============================================================\n",
    "\n",
    "# --- Core Imports ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "# --- ML / Image Processing ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "# --- Text & Sentiment ---\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "# --- Paths ---\n",
    "base = Path.cwd().parent\n",
    "processed_path = base / \"data\" / \"processed\"\n",
    "\n",
    "# --- Load Cleaned Dataset ---\n",
    "df = pd.read_parquet(processed_path / \"youtube_clean_final.parquet\")\n",
    "print(\"‚úÖ Loaded cleaned dataset:\" , df.shape)\n",
    "\n",
    "# --- Device & ResNet50 Model Setup (for Thumbnail Features) ---\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load pretrained ResNet50 (ImageNet weights)\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet50.fc = nn.Identity()  # remove final classifier\n",
    "resnet50 = resnet50.to(device)\n",
    "resnet50.eval()\n",
    "\n",
    "# Define preprocessing transform (ImageNet normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "print(\"‚úÖ ResNet50 loaded and ready for image feature extraction.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c138b9",
   "metadata": {},
   "source": [
    "# Basic Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8136c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean title column ---\n",
    "df[\"title\"] = df[\"title\"].astype(str).str.strip()\n",
    "print(\"Sample titles:\")\n",
    "print(df[\"title\"].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476d99df",
   "metadata": {},
   "source": [
    "# Structured Title Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeead73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Handcrafted title features ---\n",
    "df[\"title_length\"] = df[\"title\"].apply(len)\n",
    "df[\"word_count\"] = df[\"title\"].apply(lambda x: len(x.split()))\n",
    "df[\"caps_ratio\"] = df[\"title\"].apply(lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n",
    "df[\"has_question\"] = df[\"title\"].apply(lambda x: int(\"?\" in x))\n",
    "df[\"has_exclamation\"] = df[\"title\"].apply(lambda x: int(\"!\" in x))\n",
    "df[\"has_number\"] = df[\"title\"].apply(lambda x: int(any(ch.isdigit() for ch in x)))\n",
    "df[\"avg_word_len\"] = df[\"title\"].apply(lambda x: np.mean([len(w) for w in x.split()]) if len(x.split()) > 0 else 0)\n",
    "\n",
    "print(\"‚úÖ Added basic title features.\")\n",
    "df[[\"title\", \"title_length\", \"word_count\", \"caps_ratio\", \"has_question\", \"has_exclamation\", \"has_number\", \"avg_word_len\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1831d0",
   "metadata": {},
   "source": [
    "# Sentiment Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sentiment analysis ---\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "df[\"sentiment_vader\"] = df[\"title\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\n",
    "\n",
    "print(\"‚úÖ Added sentiment feature.\")\n",
    "df[[\"title\", \"sentiment_vader\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5386cfd8",
   "metadata": {},
   "source": [
    "# Structured Feature Matrix + Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Structured features ---\n",
    "structured_features = [\n",
    "    \"title_length\", \"word_count\", \"caps_ratio\",\n",
    "    \"has_question\", \"has_exclamation\", \"has_number\", \"avg_word_len\",\n",
    "    \"sentiment_vader\",\n",
    "    \"subscribers\"\n",
    "]\n",
    "\n",
    "X_structured = df[structured_features].copy()\n",
    "\n",
    "# --- Targets ---\n",
    "y_reg = df[\"views_per_subscriber\"]       # regression target (continuous)\n",
    "y_clf = (df[\"views_per_subscriber\"] >= df[\"views_per_subscriber\"].quantile(0.75)).astype(int)  # top 25% success\n",
    "\n",
    "print(\"Structured feature matrix:\", X_structured.shape)\n",
    "print(\"Regression target shape:\", y_reg.shape)\n",
    "print(\"Classification target distribution:\\n\", y_clf.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d85829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Handle outliers for regression target ---\n",
    "\n",
    "# Option 1: Clip extreme values (simple and intuitive)\n",
    "df[\"views_per_subscriber\"] = np.clip(df[\"views_per_subscriber\"], 0, 500)\n",
    "\n",
    "# Option 2 (alternative): Use log transform for smoother distribution\n",
    "# df[\"views_per_subscriber_log\"] = np.log1p(df[\"views_per_subscriber\"])\n",
    "\n",
    "# Then redefine regression target variable to use this cleaned version\n",
    "y_reg = df[\"views_per_subscriber\"]\n",
    "\n",
    "# (If you used log version, change above line to y_reg = df[\"views_per_subscriber_log\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740205b",
   "metadata": {},
   "source": [
    "# Save Structured Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a85928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save structured features and targets ---\n",
    "X_structured.to_parquet(processed_path / \"youtube_features_structured.parquet\", index=False)\n",
    "y_reg.to_frame(\"views_per_subscriber\").to_parquet(processed_path / \"youtube_target_regression.parquet\", index=False)\n",
    "y_clf.to_frame(\"high_clickability\").to_parquet(processed_path / \"youtube_target_classification.parquet\", index=False)\n",
    "\n",
    "print(\"‚úÖ Saved structured features and targets.\")\n",
    "print(\"‚úÖ Saved cleaned regression target to:\", processed_path / \"youtube_target_regression.parquet\")\n",
    "print(\"‚úÖ Saved cleaned classification target to:\", processed_path / \"youtube_target_classification.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d56a7f2",
   "metadata": {},
   "source": [
    "# TF-IDF Text Features (Unigrams + Bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# --- TF-IDF setup ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(df[\"title\"])\n",
    "print(\"Raw TF-IDF shape:\", tfidf_matrix.shape)\n",
    "\n",
    "# --- Dimensionality reduction (TruncatedSVD) ---\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "tfidf_reduced = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "print(\"Reduced TF-IDF shape:\", tfidf_reduced.shape)\n",
    "\n",
    "# --- Convert to DataFrame ---\n",
    "tfidf_cols = [f\"tfidf_comp_{i+1}\" for i in range(tfidf_reduced.shape[1])]\n",
    "X_tfidf = pd.DataFrame(tfidf_reduced, columns=tfidf_cols)\n",
    "\n",
    "X_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1846549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what each component means\n",
    "terms = tfidf.get_feature_names_out()\n",
    "for i, comp in enumerate(svd.components_[:5]):  # first 5 components\n",
    "    top_terms = [terms[x] for x in comp.argsort()[-10:][::-1]]\n",
    "    print(f\"Component {i+1}: {', '.join(top_terms)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd46259",
   "metadata": {},
   "source": [
    "# Save TF-IDF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save reduced TF-IDF features ---\n",
    "X_tfidf.to_parquet(processed_path / \"youtube_features_text.parquet\", index=False)\n",
    "\n",
    "print(\"‚úÖ Saved text-based TF-IDF features to:\", processed_path / \"youtube_features_text.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f516369",
   "metadata": {},
   "source": [
    "# Extract Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76736b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Downloads thumbnail and returns a 2048-D ResNet50 embedding. ---\n",
    "\n",
    "def extract_features_from_url(url: str) -> np.ndarray:\n",
    "    try:\n",
    "        if not isinstance(url, str) or not url.startswith(\"http\"):\n",
    "            raise ValueError(\"Invalid URL\")\n",
    "        # Try high-quality thumbnail if available\n",
    "        url_hq = url.replace(\"/default.jpg\", \"/hqdefault.jpg\")\n",
    "        # Download image\n",
    "        response = requests.get(url_hq, timeout=8)\n",
    "        response.raise_for_status()\n",
    "        # Decode image\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "        # Extract ResNet embedding\n",
    "        with torch.no_grad():\n",
    "            features = resnet50(img_tensor).cpu().numpy().flatten()\n",
    "        return features.astype(np.float32)\n",
    "\n",
    "    except (requests.exceptions.RequestException, UnidentifiedImageError, ValueError):\n",
    "        # Return zero vector if the image is missing or invalid\n",
    "        return np.zeros(2048, dtype=np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Applies extraction with a progress bar ---\n",
    "\n",
    "tqdm.pandas(desc=\"Extracting ResNet features\")\n",
    "df[\"resnet_features\"] = df[\"thumbnail_link\"].progress_apply(extract_features_from_url)\n",
    "\n",
    "# Count failed downloads\n",
    "fail_count = sum(np.all(f == 0) for f in df[\"resnet_features\"])\n",
    "print(f\"‚ö†Ô∏è Failed to download or decode {fail_count:,} thumbnails \"\n",
    "      f\"({100*fail_count/len(df):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a8cdd",
   "metadata": {},
   "source": [
    "# Apply PCA (dimensionality reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacks all 2048-D feature vectors into one big matrix.\n",
    "# Uses PCA to reduce them to 50 features while keeping ‚âà 95 % of the important variance.\n",
    "\n",
    "# --- Remove old PCA columns ---\n",
    "pca_cols = [c for c in df.columns if c.startswith(\"pca_\")]\n",
    "if pca_cols:\n",
    "    df = df.drop(columns=pca_cols)\n",
    "    \n",
    "# --- PCA Computation ---\n",
    "X = np.vstack(df[\"resnet_features\"].values)\n",
    "print(\"Raw feature matrix shape:\", X.shape)\n",
    "\n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "df_pca = pd.DataFrame(X_pca, columns=[f\"pca_{i+1}\" for i in range(50)])\n",
    "df = pd.concat([df.reset_index(drop=True), df_pca], axis=1)\n",
    "\n",
    "print(\"‚úÖ PCA recomputed ‚Üí shape:\", df_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0bdfb0",
   "metadata": {},
   "source": [
    "# Save Image Features Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98166712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as \"youtube_features_image.parquet\"\n",
    "\n",
    "# Keep only the PCA columns\n",
    "pca_cols = [f\"pca_{i}\" for i in range(1, 51)]\n",
    "df_pure_image = df[pca_cols].copy()\n",
    "df_pure_image.to_parquet(processed_path / \"youtube_features_image.parquet\", index=False)\n",
    "\n",
    "print(\"‚úÖ Saved pure thumbnail dataset to:\", processed_path / \"youtube_features_image.parquet\")\n",
    "print(\"Shape:\", df_pure_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify saved image feature dataset\n",
    "\n",
    "df_check = pd.read_parquet(processed_path / \"youtube_features_image.parquet\")\n",
    "print(f\"‚úÖ Loaded {len(df_check):,} rows √ó {len(df_check.columns)} columns\")\n",
    "print(\"Sample columns:\", df_check.columns[-10:].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71cf02",
   "metadata": {},
   "source": [
    "# Summary Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc43d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all saved feature datasets\n",
    "print(\"‚úÖ Summary of saved datasets:\")\n",
    "\n",
    "print(f\"‚Ä¢ Structured features:       {X_structured.shape}\")\n",
    "print(f\"‚Ä¢ Text (TF-IDF) features:    {X_tfidf.shape}\")\n",
    "print(f\"‚Ä¢ Image (PCA) features:      {df_pure_image.shape}\")\n",
    "print(f\"‚Ä¢ Regression target:         {y_reg.shape}\")\n",
    "print(f\"‚Ä¢ Classification target:     {y_clf.shape}\")\n",
    "\n",
    "print(\"\\nüìÇ All datasets saved under:\")\n",
    "print(processed_path.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_hw1)",
   "language": "python",
   "name": "ml_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
