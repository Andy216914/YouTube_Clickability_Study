{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b88559",
   "metadata": {},
   "source": [
    "# Setup & Load Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ba13e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "âœ… Loaded cleaned dataset: (5742, 19)\n",
      "âœ… ResNet50 loaded and ready for image feature extraction.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>views_per_subscriber</th>\n",
       "      <th>views_per_subscriber_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0CMnp02rNY</td>\n",
       "      <td>18.11.06</td>\n",
       "      <td>Mindy Kaling's Daughter Had the Perfect Reacti...</td>\n",
       "      <td>TheEllenShow</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-06-04 13:00:00+00:00</td>\n",
       "      <td>ellen|\"ellen degeneres\"|\"the ellen show\"|\"elle...</td>\n",
       "      <td>800359</td>\n",
       "      <td>9773</td>\n",
       "      <td>332</td>\n",
       "      <td>423</td>\n",
       "      <td>https://i.ytimg.com/vi/-0CMnp02rNY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ocean's 8 star Mindy Kaling dished on bringing...</td>\n",
       "      <td>2.376002e+07</td>\n",
       "      <td>0.033685</td>\n",
       "      <td>0.033130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0NYY8cqdiQ</td>\n",
       "      <td>18.01.02</td>\n",
       "      <td>Megan Mullally Didn't Notice the Interesting P...</td>\n",
       "      <td>TheEllenShow</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-01-29 14:00:39+00:00</td>\n",
       "      <td>megan mullally|\"megan\"|\"mullally\"|\"will and gr...</td>\n",
       "      <td>563746</td>\n",
       "      <td>4429</td>\n",
       "      <td>54</td>\n",
       "      <td>94</td>\n",
       "      <td>https://i.ytimg.com/vi/-0NYY8cqdiQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ellen and Megan Mullally have known each other...</td>\n",
       "      <td>2.376002e+07</td>\n",
       "      <td>0.023727</td>\n",
       "      <td>0.023450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1Hm41N0dUs</td>\n",
       "      <td>18.01.05</td>\n",
       "      <td>Cast of Avengers: Infinity War Draws Their Cha...</td>\n",
       "      <td>Jimmy Kimmel Live</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-04-27 07:30:02+00:00</td>\n",
       "      <td>jimmy|\"jimmy kimmel\"|\"jimmy kimmel live\"|\"late...</td>\n",
       "      <td>2058516</td>\n",
       "      <td>41248</td>\n",
       "      <td>580</td>\n",
       "      <td>1484</td>\n",
       "      <td>https://i.ytimg.com/vi/-1Hm41N0dUs/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Benedict Cumberbatch, Don Cheadle, Elizabeth O...</td>\n",
       "      <td>1.126290e+07</td>\n",
       "      <td>0.182770</td>\n",
       "      <td>0.167859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1yT-K3c6YI</td>\n",
       "      <td>17.02.12</td>\n",
       "      <td>YOUTUBER QUIZ + TRUTH OR DARE W/ THE MERRELL T...</td>\n",
       "      <td>Molly Burke</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-28 18:30:43+00:00</td>\n",
       "      <td>youtube quiz|\"youtuber quiz\"|\"truth or dare\"|\"...</td>\n",
       "      <td>231341</td>\n",
       "      <td>7734</td>\n",
       "      <td>212</td>\n",
       "      <td>846</td>\n",
       "      <td>https://i.ytimg.com/vi/-1yT-K3c6YI/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Check out the video we did on the Merrell Twin...</td>\n",
       "      <td>2.740040e+05</td>\n",
       "      <td>0.844295</td>\n",
       "      <td>0.612097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2RVw2_QyxQ</td>\n",
       "      <td>17.16.11</td>\n",
       "      <td>2017 Champions Showdown: Day 3</td>\n",
       "      <td>Saint Louis Chess Club</td>\n",
       "      <td>27</td>\n",
       "      <td>2017-11-12 02:39:01+00:00</td>\n",
       "      <td>Chess|\"Saint Louis\"|\"Club\"</td>\n",
       "      <td>71089</td>\n",
       "      <td>460</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>https://i.ytimg.com/vi/-2RVw2_QyxQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The Saint Louis Chess Club hosts a series of f...</td>\n",
       "      <td>1.477180e+05</td>\n",
       "      <td>0.481245</td>\n",
       "      <td>0.392883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  -0CMnp02rNY      18.11.06   \n",
       "1  -0NYY8cqdiQ      18.01.02   \n",
       "2  -1Hm41N0dUs      18.01.05   \n",
       "3  -1yT-K3c6YI      17.02.12   \n",
       "4  -2RVw2_QyxQ      17.16.11   \n",
       "\n",
       "                                               title           channel_title  \\\n",
       "0  Mindy Kaling's Daughter Had the Perfect Reacti...            TheEllenShow   \n",
       "1  Megan Mullally Didn't Notice the Interesting P...            TheEllenShow   \n",
       "2  Cast of Avengers: Infinity War Draws Their Cha...       Jimmy Kimmel Live   \n",
       "3  YOUTUBER QUIZ + TRUTH OR DARE W/ THE MERRELL T...             Molly Burke   \n",
       "4                     2017 Champions Showdown: Day 3  Saint Louis Chess Club   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           24 2018-06-04 13:00:00+00:00   \n",
       "1           24 2018-01-29 14:00:39+00:00   \n",
       "2           23 2018-04-27 07:30:02+00:00   \n",
       "3           22 2017-11-28 18:30:43+00:00   \n",
       "4           27 2017-11-12 02:39:01+00:00   \n",
       "\n",
       "                                                tags    views  likes  \\\n",
       "0  ellen|\"ellen degeneres\"|\"the ellen show\"|\"elle...   800359   9773   \n",
       "1  megan mullally|\"megan\"|\"mullally\"|\"will and gr...   563746   4429   \n",
       "2  jimmy|\"jimmy kimmel\"|\"jimmy kimmel live\"|\"late...  2058516  41248   \n",
       "3  youtube quiz|\"youtuber quiz\"|\"truth or dare\"|\"...   231341   7734   \n",
       "4                         Chess|\"Saint Louis\"|\"Club\"    71089    460   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0       332            423  https://i.ytimg.com/vi/-0CMnp02rNY/default.jpg   \n",
       "1        54             94  https://i.ytimg.com/vi/-0NYY8cqdiQ/default.jpg   \n",
       "2       580           1484  https://i.ytimg.com/vi/-1Hm41N0dUs/default.jpg   \n",
       "3       212            846  https://i.ytimg.com/vi/-1yT-K3c6YI/default.jpg   \n",
       "4        27             20  https://i.ytimg.com/vi/-2RVw2_QyxQ/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description   subscribers  \\\n",
       "0  Ocean's 8 star Mindy Kaling dished on bringing...  2.376002e+07   \n",
       "1  Ellen and Megan Mullally have known each other...  2.376002e+07   \n",
       "2  Benedict Cumberbatch, Don Cheadle, Elizabeth O...  1.126290e+07   \n",
       "3  Check out the video we did on the Merrell Twin...  2.740040e+05   \n",
       "4  The Saint Louis Chess Club hosts a series of f...  1.477180e+05   \n",
       "\n",
       "   views_per_subscriber  views_per_subscriber_log  \n",
       "0              0.033685                  0.033130  \n",
       "1              0.023727                  0.023450  \n",
       "2              0.182770                  0.167859  \n",
       "3              0.844295                  0.612097  \n",
       "4              0.481245                  0.392883  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Setup & Environment for Feature Engineering\n",
    "# Generates 5 datasets:\n",
    "# structured, text, image, regression, classification\n",
    "# ============================================================\n",
    "\n",
    "# --- Core Imports ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "# --- ML / Image Processing ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "%pip install torchvision --quiet\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "# --- Text & Sentiment ---\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "# --- Paths ---\n",
    "base = Path.cwd().parent\n",
    "processed_path = base / \"data\" / \"processed\"\n",
    "\n",
    "# --- Load Cleaned Dataset ---\n",
    "df = pd.read_parquet(processed_path / \"youtube_clean_final.parquet\")\n",
    "print(\"âœ… Loaded cleaned dataset:\" , df.shape)\n",
    "\n",
    "# --- Device & ResNet50 Model Setup (for Thumbnail Features) ---\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load pretrained ResNet50 (ImageNet weights)\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet50.fc = nn.Identity()  # remove final classifier\n",
    "resnet50 = resnet50.to(device)\n",
    "resnet50.eval()\n",
    "\n",
    "# Define preprocessing transform (ImageNet normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "print(\"âœ… ResNet50 loaded and ready for image feature extraction.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c138b9",
   "metadata": {},
   "source": [
    "# Basic Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8136c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample titles:\n",
      "0    Mindy Kaling's Daughter Had the Perfect Reacti...\n",
      "1    Megan Mullally Didn't Notice the Interesting P...\n",
      "2    Cast of Avengers: Infinity War Draws Their Cha...\n",
      "3    YOUTUBER QUIZ + TRUTH OR DARE W/ THE MERRELL T...\n",
      "4                       2017 Champions Showdown: Day 3\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Clean title column ---\n",
    "df[\"title\"] = df[\"title\"].astype(str).str.strip()\n",
    "print(\"Sample titles:\")\n",
    "print(df[\"title\"].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476d99df",
   "metadata": {},
   "source": [
    "# Structured Title Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebeead73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Added basic title features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>caps_ratio</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_exclamation</th>\n",
       "      <th>has_number</th>\n",
       "      <th>avg_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mindy Kaling's Daughter Had the Perfect Reacti...</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Megan Mullally Didn't Notice the Interesting P...</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cast of Avengers: Infinity War Draws Their Cha...</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOUTUBER QUIZ + TRUTH OR DARE W/ THE MERRELL T...</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017 Champions Showdown: Day 3</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  title_length  \\\n",
       "0  Mindy Kaling's Daughter Had the Perfect Reacti...            74   \n",
       "1  Megan Mullally Didn't Notice the Interesting P...            75   \n",
       "2  Cast of Avengers: Infinity War Draws Their Cha...            53   \n",
       "3  YOUTUBER QUIZ + TRUTH OR DARE W/ THE MERRELL T...            51   \n",
       "4                     2017 Champions Showdown: Day 3            30   \n",
       "\n",
       "   word_count  caps_ratio  has_question  has_exclamation  has_number  \\\n",
       "0          11    0.121622             0                0           0   \n",
       "1          10    0.106667             0                0           0   \n",
       "2           8    0.132075             0                0           0   \n",
       "3          10    0.764706             0                1           0   \n",
       "4           5    0.100000             0                0           1   \n",
       "\n",
       "   avg_word_len  \n",
       "0      5.818182  \n",
       "1      6.600000  \n",
       "2      5.750000  \n",
       "3      4.200000  \n",
       "4      5.200000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Handcrafted title features ---\n",
    "df[\"title_length\"] = df[\"title\"].apply(len)\n",
    "df[\"word_count\"] = df[\"title\"].apply(lambda x: len(x.split()))\n",
    "df[\"caps_ratio\"] = df[\"title\"].apply(lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n",
    "df[\"has_question\"] = df[\"title\"].apply(lambda x: int(\"?\" in x))\n",
    "df[\"has_exclamation\"] = df[\"title\"].apply(lambda x: int(\"!\" in x))\n",
    "df[\"has_number\"] = df[\"title\"].apply(lambda x: int(any(ch.isdigit() for ch in x)))\n",
    "df[\"avg_word_len\"] = df[\"title\"].apply(lambda x: np.mean([len(w) for w in x.split()]) if len(x.split()) > 0 else 0)\n",
    "\n",
    "print(\"âœ… Added basic title features.\")\n",
    "df[[\"title\", \"title_length\", \"word_count\", \"caps_ratio\", \"has_question\", \"has_exclamation\", \"has_number\", \"avg_word_len\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1831d0",
   "metadata": {},
   "source": [
    "# Sentiment Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89f8294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Added sentiment feature.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mindy Kaling's Daughter Had the Perfect Reacti...</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Megan Mullally Didn't Notice the Interesting P...</td>\n",
       "      <td>-0.3089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cast of Avengers: Infinity War Draws Their Cha...</td>\n",
       "      <td>-0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOUTUBER QUIZ + TRUTH OR DARE W/ THE MERRELL T...</td>\n",
       "      <td>0.5147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017 Champions Showdown: Day 3</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  sentiment_vader\n",
       "0  Mindy Kaling's Daughter Had the Perfect Reacti...           0.5719\n",
       "1  Megan Mullally Didn't Notice the Interesting P...          -0.3089\n",
       "2  Cast of Avengers: Infinity War Draws Their Cha...          -0.5994\n",
       "3  YOUTUBER QUIZ + TRUTH OR DARE W/ THE MERRELL T...           0.5147\n",
       "4                     2017 Champions Showdown: Day 3           0.5267"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Sentiment analysis ---\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "df[\"sentiment_vader\"] = df[\"title\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\n",
    "\n",
    "print(\"âœ… Added sentiment feature.\")\n",
    "df[[\"title\", \"sentiment_vader\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5386cfd8",
   "metadata": {},
   "source": [
    "# Structured Feature Matrix + Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3c1f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured feature matrix: (5742, 9)\n",
      "Regression target shape: (5742,)\n",
      "Classification target distribution:\n",
      " views_per_subscriber\n",
      "0    0.749913\n",
      "1    0.250087\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- Structured features ---\n",
    "structured_features = [\n",
    "    \"title_length\", \"word_count\", \"caps_ratio\",\n",
    "    \"has_question\", \"has_exclamation\", \"has_number\", \"avg_word_len\",\n",
    "    \"sentiment_vader\",\n",
    "    \"subscribers\"\n",
    "]\n",
    "\n",
    "X_structured = df[structured_features].copy()\n",
    "\n",
    "# --- Targets ---\n",
    "y_reg = df[\"views_per_subscriber\"]       # regression target (continuous)\n",
    "y_clf = (df[\"views_per_subscriber\"] >= df[\"views_per_subscriber\"].quantile(0.75)).astype(int)  # top 25% success\n",
    "\n",
    "print(\"Structured feature matrix:\", X_structured.shape)\n",
    "print(\"Regression target shape:\", y_reg.shape)\n",
    "print(\"Classification target distribution:\\n\", y_clf.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d85829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Handle outliers for regression target ---\n",
    "\n",
    "# Option 1: Clip extreme values (simple and intuitive)\n",
    "df[\"views_per_subscriber\"] = np.clip(df[\"views_per_subscriber\"], 0, 500)\n",
    "\n",
    "# Option 2 (alternative): Use log transform for smoother distribution\n",
    "# df[\"views_per_subscriber_log\"] = np.log1p(df[\"views_per_subscriber\"])\n",
    "\n",
    "# Then redefine regression target variable to use this cleaned version\n",
    "y_reg = df[\"views_per_subscriber\"]\n",
    "\n",
    "# (If you used log version, change above line to y_reg = df[\"views_per_subscriber_log\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740205b",
   "metadata": {},
   "source": [
    "# Save Structured Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a85928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved structured features and targets.\n",
      "âœ… Saved cleaned regression target to: c:\\Users\\bhada\\Documents\\GitHub\\YouTube_Clickability_Study\\data\\processed\\youtube_target_regression.parquet\n",
      "âœ… Saved cleaned classification target to: c:\\Users\\bhada\\Documents\\GitHub\\YouTube_Clickability_Study\\data\\processed\\youtube_target_classification.parquet\n"
     ]
    }
   ],
   "source": [
    "# --- Save structured features and targets ---\n",
    "X_structured.to_parquet(processed_path / \"youtube_features_structured.parquet\", index=False)\n",
    "y_reg.to_frame(\"views_per_subscriber\").to_parquet(processed_path / \"youtube_target_regression.parquet\", index=False)\n",
    "y_clf.to_frame(\"high_clickability\").to_parquet(processed_path / \"youtube_target_classification.parquet\", index=False)\n",
    "\n",
    "print(\"âœ… Saved structured features and targets.\")\n",
    "print(\"âœ… Saved cleaned regression target to:\", processed_path / \"youtube_target_regression.parquet\")\n",
    "print(\"âœ… Saved cleaned classification target to:\", processed_path / \"youtube_target_classification.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d56a7f2",
   "metadata": {},
   "source": [
    "# TF-IDF Text Features (Unigrams + Bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618b6aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw TF-IDF shape: (5742, 1000)\n",
      "Reduced TF-IDF shape: (5742, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_comp_1</th>\n",
       "      <th>tfidf_comp_2</th>\n",
       "      <th>tfidf_comp_3</th>\n",
       "      <th>tfidf_comp_4</th>\n",
       "      <th>tfidf_comp_5</th>\n",
       "      <th>tfidf_comp_6</th>\n",
       "      <th>tfidf_comp_7</th>\n",
       "      <th>tfidf_comp_8</th>\n",
       "      <th>tfidf_comp_9</th>\n",
       "      <th>tfidf_comp_10</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_comp_41</th>\n",
       "      <th>tfidf_comp_42</th>\n",
       "      <th>tfidf_comp_43</th>\n",
       "      <th>tfidf_comp_44</th>\n",
       "      <th>tfidf_comp_45</th>\n",
       "      <th>tfidf_comp_46</th>\n",
       "      <th>tfidf_comp_47</th>\n",
       "      <th>tfidf_comp_48</th>\n",
       "      <th>tfidf_comp_49</th>\n",
       "      <th>tfidf_comp_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008023</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.021451</td>\n",
       "      <td>0.021926</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.020432</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152593</td>\n",
       "      <td>0.105763</td>\n",
       "      <td>-0.016033</td>\n",
       "      <td>0.039567</td>\n",
       "      <td>-0.121613</td>\n",
       "      <td>0.124725</td>\n",
       "      <td>-0.055770</td>\n",
       "      <td>0.075234</td>\n",
       "      <td>-0.116634</td>\n",
       "      <td>-0.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.009124</td>\n",
       "      <td>0.016396</td>\n",
       "      <td>0.013081</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>-0.002582</td>\n",
       "      <td>-0.009785</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>-0.001931</td>\n",
       "      <td>-0.011767</td>\n",
       "      <td>-0.023423</td>\n",
       "      <td>-0.006530</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>-0.010738</td>\n",
       "      <td>-0.006718</td>\n",
       "      <td>-0.012869</td>\n",
       "      <td>0.005131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010647</td>\n",
       "      <td>-0.010526</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>-0.014330</td>\n",
       "      <td>-0.005137</td>\n",
       "      <td>-0.030994</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>-0.002526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263607</td>\n",
       "      <td>-0.058746</td>\n",
       "      <td>0.033722</td>\n",
       "      <td>-0.141856</td>\n",
       "      <td>0.011770</td>\n",
       "      <td>0.208311</td>\n",
       "      <td>-0.078890</td>\n",
       "      <td>-0.121032</td>\n",
       "      <td>0.063431</td>\n",
       "      <td>-0.285299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003308</td>\n",
       "      <td>-0.002960</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>0.008354</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013322</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>-0.000899</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.011466</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>-0.001436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>-0.014160</td>\n",
       "      <td>0.172012</td>\n",
       "      <td>0.249537</td>\n",
       "      <td>0.296775</td>\n",
       "      <td>-0.027703</td>\n",
       "      <td>-0.003996</td>\n",
       "      <td>-0.180619</td>\n",
       "      <td>0.016951</td>\n",
       "      <td>0.076816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>-0.010501</td>\n",
       "      <td>0.023246</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>-0.012430</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>0.033865</td>\n",
       "      <td>0.024061</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>-0.036545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tfidf_comp_1  tfidf_comp_2  tfidf_comp_3  tfidf_comp_4  tfidf_comp_5  \\\n",
       "0      0.008023      0.000299      0.021451      0.021926      0.006446   \n",
       "1      0.000881      0.000389      0.009124      0.016396      0.013081   \n",
       "2      0.010647     -0.010526      0.007540      0.021256     -0.014330   \n",
       "3      0.003308     -0.002960      0.005910      0.005595     -0.000852   \n",
       "4      0.020000     -0.014160      0.172012      0.249537      0.296775   \n",
       "\n",
       "   tfidf_comp_6  tfidf_comp_7  tfidf_comp_8  tfidf_comp_9  tfidf_comp_10  ...  \\\n",
       "0      0.001927      0.006493      0.000916      0.020432       0.009336  ...   \n",
       "1      0.001009     -0.002582     -0.009785      0.002011       0.005803  ...   \n",
       "2     -0.005137     -0.030994     -0.000343      0.002833      -0.002526  ...   \n",
       "3      0.000878      0.001912      0.002622      0.004437       0.008354  ...   \n",
       "4     -0.027703     -0.003996     -0.180619      0.016951       0.076816  ...   \n",
       "\n",
       "   tfidf_comp_41  tfidf_comp_42  tfidf_comp_43  tfidf_comp_44  tfidf_comp_45  \\\n",
       "0       0.152593       0.105763      -0.016033       0.039567      -0.121613   \n",
       "1       0.005325      -0.001931      -0.011767      -0.023423      -0.006530   \n",
       "2       0.263607      -0.058746       0.033722      -0.141856       0.011770   \n",
       "3      -0.013322       0.002138      -0.000899      -0.000225       0.000905   \n",
       "4       0.005867      -0.010501       0.023246       0.011764      -0.012430   \n",
       "\n",
       "   tfidf_comp_46  tfidf_comp_47  tfidf_comp_48  tfidf_comp_49  tfidf_comp_50  \n",
       "0       0.124725      -0.055770       0.075234      -0.116634      -0.063000  \n",
       "1       0.000859      -0.010738      -0.006718      -0.012869       0.005131  \n",
       "2       0.208311      -0.078890      -0.121032       0.063431      -0.285299  \n",
       "3       0.011466       0.006203       0.005829       0.006671      -0.001436  \n",
       "4       0.013665       0.033865       0.024061       0.039195      -0.036545  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# --- TF-IDF setup ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(df[\"title\"])\n",
    "print(\"Raw TF-IDF shape:\", tfidf_matrix.shape)\n",
    "\n",
    "# --- Dimensionality reduction (TruncatedSVD) ---\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "tfidf_reduced = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "print(\"Reduced TF-IDF shape:\", tfidf_reduced.shape)\n",
    "\n",
    "# --- Convert to DataFrame ---\n",
    "tfidf_cols = [f\"tfidf_comp_{i+1}\" for i in range(tfidf_reduced.shape[1])]\n",
    "X_tfidf = pd.DataFrame(tfidf_reduced, columns=tfidf_cols)\n",
    "\n",
    "X_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1846549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 1: official, trailer, video, official trailer, official video, hd, trailer hd, netflix, hd netflix, music\n",
      "Component 2: video, official video, music, music video, official, official music, ft, lyric, lyric video, video ft\n",
      "Component 3: 2018, 2017, new, vs, live, game, day, best, awards, 10\n",
      "Component 4: 2017, new, star, wars, star wars, vs, live, makeup, jedi, best\n",
      "Component 5: 2017, vs, best, 10, highlights, awards, nfl, game, live, christmas\n"
     ]
    }
   ],
   "source": [
    "# see what each component means\n",
    "terms = tfidf.get_feature_names_out()\n",
    "for i, comp in enumerate(svd.components_[:5]):  # first 5 components\n",
    "    top_terms = [terms[x] for x in comp.argsort()[-10:][::-1]]\n",
    "    print(f\"Component {i+1}: {', '.join(top_terms)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd46259",
   "metadata": {},
   "source": [
    "# Save TF-IDF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff02a2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved text-based TF-IDF features to: c:\\Users\\bhada\\Documents\\GitHub\\YouTube_Clickability_Study\\data\\processed\\youtube_features_text.parquet\n"
     ]
    }
   ],
   "source": [
    "# --- Save reduced TF-IDF features ---\n",
    "X_tfidf.to_parquet(processed_path / \"youtube_features_text.parquet\", index=False)\n",
    "\n",
    "print(\"âœ… Saved text-based TF-IDF features to:\", processed_path / \"youtube_features_text.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f516369",
   "metadata": {},
   "source": [
    "# Extract Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e76736b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Downloads thumbnail and returns a 2048-D ResNet50 embedding. ---\n",
    "\n",
    "def extract_features_from_url(url: str) -> np.ndarray:\n",
    "    try:\n",
    "        if not isinstance(url, str) or not url.startswith(\"http\"):\n",
    "            raise ValueError(\"Invalid URL\")\n",
    "        # Try high-quality thumbnail if available\n",
    "        url_hq = url.replace(\"/default.jpg\", \"/hqdefault.jpg\")\n",
    "        # Download image\n",
    "        response = requests.get(url_hq, timeout=8)\n",
    "        response.raise_for_status()\n",
    "        # Decode image\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "        # Extract ResNet embedding\n",
    "        with torch.no_grad():\n",
    "            features = resnet50(img_tensor).cpu().numpy().flatten()\n",
    "        return features.astype(np.float32)\n",
    "\n",
    "    except (requests.exceptions.RequestException, UnidentifiedImageError, ValueError):\n",
    "        # Return zero vector if the image is missing or invalid\n",
    "        return np.zeros(2048, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c03042e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting ResNet features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5742/5742 [40:37<00:00,  2.36it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to download or decode 534 thumbnails (9.3%)\n"
     ]
    }
   ],
   "source": [
    "# --- Applies extraction with a progress bar ---\n",
    "\n",
    "tqdm.pandas(desc=\"Extracting ResNet features\")\n",
    "df[\"resnet_features\"] = df[\"thumbnail_link\"].progress_apply(extract_features_from_url)\n",
    "\n",
    "# Count failed downloads\n",
    "fail_count = sum(np.all(f == 0) for f in df[\"resnet_features\"])\n",
    "print(f\"âš ï¸ Failed to download or decode {fail_count:,} thumbnails \"\n",
    "      f\"({100*fail_count/len(df):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a8cdd",
   "metadata": {},
   "source": [
    "# Apply PCA (dimensionality reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6fe45d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature matrix shape: (5742, 2048)\n",
      "âœ… PCA recomputed â†’ shape: (5742, 50)\n"
     ]
    }
   ],
   "source": [
    "# Stacks all 2048-D feature vectors into one big matrix.\n",
    "# Uses PCA to reduce them to 50 features while keeping â‰ˆ 95 % of the important variance.\n",
    "\n",
    "# --- Remove old PCA columns ---\n",
    "pca_cols = [c for c in df.columns if c.startswith(\"pca_\")]\n",
    "if pca_cols:\n",
    "    df = df.drop(columns=pca_cols)\n",
    "\n",
    "# --- PCA Computation ---\n",
    "X = np.vstack(df[\"resnet_features\"].values)\n",
    "print(\"Raw feature matrix shape:\", X.shape)\n",
    "\n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "df_pca = pd.DataFrame(X_pca, columns=[f\"pca_{i+1}\" for i in range(50)])\n",
    "df = pd.concat([df.reset_index(drop=True), df_pca], axis=1)\n",
    "\n",
    "print(\"âœ… PCA recomputed â†’ shape:\", df_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0bdfb0",
   "metadata": {},
   "source": [
    "# Save Image Features Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98166712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved pure thumbnail dataset to: c:\\Users\\bhada\\Documents\\GitHub\\YouTube_Clickability_Study\\data\\processed\\youtube_features_image.parquet\n",
      "Shape: (5742, 50)\n"
     ]
    }
   ],
   "source": [
    "# Saving the dataset as \"youtube_features_image.parquet\"\n",
    "\n",
    "# Keep only the PCA columns\n",
    "pca_cols = [f\"pca_{i}\" for i in range(1, 51)]\n",
    "df_pure_image = df[pca_cols].copy()\n",
    "df_pure_image.to_parquet(processed_path / \"youtube_features_image.parquet\", index=False)\n",
    "\n",
    "print(\"âœ… Saved pure thumbnail dataset to:\", processed_path / \"youtube_features_image.parquet\")\n",
    "print(\"Shape:\", df_pure_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16d1e2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 5,742 rows Ã— 50 columns\n",
      "Sample columns: ['pca_41', 'pca_42', 'pca_43', 'pca_44', 'pca_45', 'pca_46', 'pca_47', 'pca_48', 'pca_49', 'pca_50']\n"
     ]
    }
   ],
   "source": [
    "# Verify saved image feature dataset\n",
    "\n",
    "df_check = pd.read_parquet(processed_path / \"youtube_features_image.parquet\")\n",
    "print(f\"âœ… Loaded {len(df_check):,} rows Ã— {len(df_check.columns)} columns\")\n",
    "print(\"Sample columns:\", df_check.columns[-10:].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71cf02",
   "metadata": {},
   "source": [
    "# Summary Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbc43d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Summary of saved datasets:\n",
      "â€¢ Structured features:       (5742, 9)\n",
      "â€¢ Text (TF-IDF) features:    (5742, 50)\n",
      "â€¢ Image (PCA) features:      (5742, 50)\n",
      "â€¢ Regression target:         (5742,)\n",
      "â€¢ Classification target:     (5742,)\n",
      "\n",
      "ðŸ“‚ All datasets saved under:\n",
      "C:\\Users\\bhada\\Documents\\GitHub\\YouTube_Clickability_Study\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "# Summary of all saved feature datasets\n",
    "print(\"âœ… Summary of saved datasets:\")\n",
    "\n",
    "print(f\"â€¢ Structured features:       {X_structured.shape}\")\n",
    "print(f\"â€¢ Text (TF-IDF) features:    {X_tfidf.shape}\")\n",
    "print(f\"â€¢ Image (PCA) features:      {df_pure_image.shape}\")\n",
    "print(f\"â€¢ Regression target:         {y_reg.shape}\")\n",
    "print(f\"â€¢ Classification target:     {y_clf.shape}\")\n",
    "\n",
    "print(\"\\nðŸ“‚ All datasets saved under:\")\n",
    "print(processed_path.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
